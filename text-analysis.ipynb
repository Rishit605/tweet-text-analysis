{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c674cda",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-06-11T06:38:42.811569Z",
     "iopub.status.busy": "2022-06-11T06:38:42.811141Z",
     "iopub.status.idle": "2022-06-11T06:38:42.830727Z",
     "shell.execute_reply": "2022-06-11T06:38:42.829682Z"
    },
    "papermill": {
     "duration": 0.032208,
     "end_time": "2022-06-11T06:38:42.832946",
     "exception": false,
     "start_time": "2022-06-11T06:38:42.800738",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/covid-19-nlp-text-classification/Corona_NLP_test.csv\n",
      "/kaggle/input/covid-19-nlp-text-classification/Corona_NLP_train.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee1435bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T06:38:42.845685Z",
     "iopub.status.busy": "2022-06-11T06:38:42.845299Z",
     "iopub.status.idle": "2022-06-11T06:38:44.774995Z",
     "shell.execute_reply": "2022-06-11T06:38:44.773989Z"
    },
    "papermill": {
     "duration": 1.938747,
     "end_time": "2022-06-11T06:38:44.777347",
     "exception": false,
     "start_time": "2022-06-11T06:38:42.838600",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import nltk\n",
    "import re \n",
    "import os \n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8747d910",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T06:38:44.790059Z",
     "iopub.status.busy": "2022-06-11T06:38:44.789662Z",
     "iopub.status.idle": "2022-06-11T06:38:45.056460Z",
     "shell.execute_reply": "2022-06-11T06:38:45.055363Z"
    },
    "papermill": {
     "duration": 0.276282,
     "end_time": "2022-06-11T06:38:45.059261",
     "exception": false,
     "start_time": "2022-06-11T06:38:44.782979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/covid-19-nlp-text-classification/Corona_NLP_train.csv', encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11e0b3f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T06:38:45.071937Z",
     "iopub.status.busy": "2022-06-11T06:38:45.071553Z",
     "iopub.status.idle": "2022-06-11T06:38:45.097788Z",
     "shell.execute_reply": "2022-06-11T06:38:45.096888Z"
    },
    "papermill": {
     "duration": 0.035203,
     "end_time": "2022-06-11T06:38:45.099993",
     "exception": false,
     "start_time": "2022-06-11T06:38:45.064790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3804</td>\n",
       "      <td>48756</td>\n",
       "      <td>ÃT: 36.319708,-82.363649</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>As news of the regionÂs first confirmed COVID...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3805</td>\n",
       "      <td>48757</td>\n",
       "      <td>35.926541,-78.753267</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Cashier at grocery store was sharing his insig...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3806</td>\n",
       "      <td>48758</td>\n",
       "      <td>Austria</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Was at the supermarket today. Didn't buy toile...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3807</td>\n",
       "      <td>48759</td>\n",
       "      <td>Atlanta, GA USA</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Due to COVID-19 our retail store and classroom...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3808</td>\n",
       "      <td>48760</td>\n",
       "      <td>BHAVNAGAR,GUJRAT</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>For corona prevention,we should stop to buy th...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3809</td>\n",
       "      <td>48761</td>\n",
       "      <td>Makati, Manila</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>All month there hasn't been crowding in the su...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3810</td>\n",
       "      <td>48762</td>\n",
       "      <td>Pitt Meadows, BC, Canada</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Due to the Covid-19 situation, we have increas...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3811</td>\n",
       "      <td>48763</td>\n",
       "      <td>Horningsea</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>#horningsea is a caring community. LetÂs ALL ...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3812</td>\n",
       "      <td>48764</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me: I don't need to stock up on food, I'll jus...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3813</td>\n",
       "      <td>48765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>ADARA Releases COVID-19 Resource Center for Tr...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    UserName  ScreenName                   Location     TweetAt  \\\n",
       "0       3799       48751                     London  16-03-2020   \n",
       "1       3800       48752                         UK  16-03-2020   \n",
       "2       3801       48753                  Vagabonds  16-03-2020   \n",
       "3       3802       48754                        NaN  16-03-2020   \n",
       "4       3803       48755                        NaN  16-03-2020   \n",
       "5       3804       48756  ÃT: 36.319708,-82.363649  16-03-2020   \n",
       "6       3805       48757       35.926541,-78.753267  16-03-2020   \n",
       "7       3806       48758                    Austria  16-03-2020   \n",
       "8       3807       48759            Atlanta, GA USA  16-03-2020   \n",
       "9       3808       48760           BHAVNAGAR,GUJRAT  16-03-2020   \n",
       "10      3809       48761             Makati, Manila  16-03-2020   \n",
       "11      3810       48762  Pitt Meadows, BC, Canada   16-03-2020   \n",
       "12      3811       48763                 Horningsea  16-03-2020   \n",
       "13      3812       48764                Chicago, IL  16-03-2020   \n",
       "14      3813       48765                        NaN  16-03-2020   \n",
       "\n",
       "                                        OriginalTweet           Sentiment  \n",
       "0   @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
       "1   advice Talk to your neighbours family to excha...            Positive  \n",
       "2   Coronavirus Australia: Woolworths to give elde...            Positive  \n",
       "3   My food stock is not the only one which is emp...            Positive  \n",
       "4   Me, ready to go at supermarket during the #COV...  Extremely Negative  \n",
       "5   As news of the regionÂs first confirmed COVID...            Positive  \n",
       "6   Cashier at grocery store was sharing his insig...            Positive  \n",
       "7   Was at the supermarket today. Didn't buy toile...             Neutral  \n",
       "8   Due to COVID-19 our retail store and classroom...            Positive  \n",
       "9   For corona prevention,we should stop to buy th...            Negative  \n",
       "10  All month there hasn't been crowding in the su...             Neutral  \n",
       "11  Due to the Covid-19 situation, we have increas...  Extremely Positive  \n",
       "12  #horningsea is a caring community. LetÂs ALL ...  Extremely Positive  \n",
       "13  Me: I don't need to stock up on food, I'll jus...            Positive  \n",
       "14  ADARA Releases COVID-19 Resource Center for Tr...            Positive  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a29ff2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T06:38:45.113882Z",
     "iopub.status.busy": "2022-06-11T06:38:45.113489Z",
     "iopub.status.idle": "2022-06-11T06:38:45.157146Z",
     "shell.execute_reply": "2022-06-11T06:38:45.155771Z"
    },
    "papermill": {
     "duration": 0.053293,
     "end_time": "2022-06-11T06:38:45.159598",
     "exception": false,
     "start_time": "2022-06-11T06:38:45.106305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41157 entries, 0 to 41156\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   UserName       41157 non-null  int64 \n",
      " 1   ScreenName     41157 non-null  int64 \n",
      " 2   Location       32567 non-null  object\n",
      " 3   TweetAt        41157 non-null  object\n",
      " 4   OriginalTweet  41157 non-null  object\n",
      " 5   Sentiment      41157 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "406e838c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T06:38:45.173662Z",
     "iopub.status.busy": "2022-06-11T06:38:45.172705Z",
     "iopub.status.idle": "2022-06-11T06:38:45.180846Z",
     "shell.execute_reply": "2022-06-11T06:38:45.179878Z"
    },
    "papermill": {
     "duration": 0.017458,
     "end_time": "2022-06-11T06:38:45.183082",
     "exception": false,
     "start_time": "2022-06-11T06:38:45.165624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "null_col = ['ScreenName', 'Location', 'TweetAt', 'Sentiment']\n",
    "df2 = df.drop(null_col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f0e9afd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T06:38:45.196659Z",
     "iopub.status.busy": "2022-06-11T06:38:45.196232Z",
     "iopub.status.idle": "2022-06-11T06:38:45.214675Z",
     "shell.execute_reply": "2022-06-11T06:38:45.213250Z"
    },
    "papermill": {
     "duration": 0.027805,
     "end_time": "2022-06-11T06:38:45.216911",
     "exception": false,
     "start_time": "2022-06-11T06:38:45.189106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41157 entries, 0 to 41156\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   UserName       41157 non-null  int64 \n",
      " 1   OriginalTweet  41157 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 643.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dae61333",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T06:38:45.230912Z",
     "iopub.status.busy": "2022-06-11T06:38:45.230528Z",
     "iopub.status.idle": "2022-06-11T06:38:45.330931Z",
     "shell.execute_reply": "2022-06-11T06:38:45.329949Z"
    },
    "papermill": {
     "duration": 0.110185,
     "end_time": "2022-06-11T06:38:45.333197",
     "exception": false,
     "start_time": "2022-06-11T06:38:45.223012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer \n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "stopwords = stopwords.words('english')\n",
    "stemmer = SnowballStemmer('english')\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "# As this dataset is fetched from twitter so it has lots of people tag in tweets\n",
    "# we will remove them \n",
    "tags = r\"@\\w*\"\n",
    "\n",
    "\n",
    "def preprocess_text(sentence, stem = False):\n",
    "    \n",
    "    sentence = [re.sub(tags, \"\", sentence)]\n",
    "    text = []\n",
    "    for word in sentence:\n",
    "        \n",
    "        if word not in stopwords:\n",
    "            \n",
    "            if stem:\n",
    "                text.append(stemmer.stem(word).lower())\n",
    "            else:\n",
    "                text.append(word.lower())\n",
    "    return tokenizer.tokenize(\" \".join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01f2ecc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T06:38:45.346984Z",
     "iopub.status.busy": "2022-06-11T06:38:45.346594Z",
     "iopub.status.idle": "2022-06-11T06:38:45.352228Z",
     "shell.execute_reply": "2022-06-11T06:38:45.351335Z"
    },
    "papermill": {
     "duration": 0.015492,
     "end_time": "2022-06-11T06:38:45.354873",
     "exception": false,
     "start_time": "2022-06-11T06:38:45.339381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "#CoronavirusFrance #restezchezvous #StayAtHome #confinement https://t.co/usmuaLq72n\n",
      "\n",
      "Preprocessed Text : ['me', 'ready', 'to', 'go', 'at', 'supermarket', 'during', 'the', 'covid19', 'outbreak', 'not', 'because', 'i', 'm', 'paranoid', 'but', 'because', 'my', 'food', 'stock', 'is', 'litteraly', 'empty', 'the', 'coronavirus', 'is', 'a', 'serious', 'thing', 'but', 'please', 'don', 't', 'panic', 'it', 'causes', 'shortage', 'coronavirusfrance', 'restezchezvous', 'stayathome', 'confinement', 'https', 't', 'co', 'usmualq72n']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Orignal Text : {df2.OriginalTweet[4]}\")\n",
    "print()\n",
    "print(f\"Preprocessed Text : {preprocess_text(df2.OriginalTweet[4])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92af3115",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T06:38:45.368617Z",
     "iopub.status.busy": "2022-06-11T06:38:45.368241Z",
     "iopub.status.idle": "2022-06-11T06:38:46.361327Z",
     "shell.execute_reply": "2022-06-11T06:38:46.360380Z"
    },
    "papermill": {
     "duration": 1.002262,
     "end_time": "2022-06-11T06:38:46.363243",
     "exception": false,
     "start_time": "2022-06-11T06:38:45.360981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>OriginalTweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>[https, t, co, ifz9fan2pa, and, https, t, co, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>[advice, talk, to, your, neighbours, family, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>[coronavirus, australia, woolworths, to, give,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>[my, food, stock, is, not, the, only, one, whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>[me, ready, to, go, at, supermarket, during, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName                                      OriginalTweet\n",
       "0      3799  [https, t, co, ifz9fan2pa, and, https, t, co, ...\n",
       "1      3800  [advice, talk, to, your, neighbours, family, t...\n",
       "2      3801  [coronavirus, australia, woolworths, to, give,...\n",
       "3      3802  [my, food, stock, is, not, the, only, one, whi...\n",
       "4      3803  [me, ready, to, go, at, supermarket, during, t..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.OriginalTweet = df2.OriginalTweet.map(preprocess_text)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12e9c706",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T06:38:46.378534Z",
     "iopub.status.busy": "2022-06-11T06:38:46.377429Z",
     "iopub.status.idle": "2022-06-11T06:38:46.382260Z",
     "shell.execute_reply": "2022-06-11T06:38:46.381495Z"
    },
    "papermill": {
     "duration": 0.014164,
     "end_time": "2022-06-11T06:38:46.384237",
     "exception": false,
     "start_time": "2022-06-11T06:38:46.370073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#this is an example vocabulary just to make concept clear\n",
    "sample_vocab = ['its', 'one', 'thing', 'I', 'dont', 'know', 'why', 'it', 'dosent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f78b28b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T06:38:46.398293Z",
     "iopub.status.busy": "2022-06-11T06:38:46.397904Z",
     "iopub.status.idle": "2022-06-11T06:41:08.842294Z",
     "shell.execute_reply": "2022-06-11T06:41:08.841156Z"
    },
    "papermill": {
     "duration": 142.454315,
     "end_time": "2022-06-11T06:41:08.844912",
     "exception": false,
     "start_time": "2022-06-11T06:38:46.390597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vocabulary of words present in dataset\n",
    "data_vocab = []\n",
    "for text in df2.OriginalTweet:\n",
    "    for word in text:\n",
    "        if word not in data_vocab:\n",
    "            data_vocab.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b261eed6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T06:41:08.859487Z",
     "iopub.status.busy": "2022-06-11T06:41:08.859012Z",
     "iopub.status.idle": "2022-06-11T06:41:08.869589Z",
     "shell.execute_reply": "2022-06-11T06:41:08.868913Z"
    },
    "papermill": {
     "duration": 0.022014,
     "end_time": "2022-06-11T06:41:08.873661",
     "exception": false,
     "start_time": "2022-06-11T06:41:08.851647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One Hot Representation for sentence \"its one thing I dont know why it doesnt\" :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 1, 0]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#function to return one-hot representation of passed text\n",
    "def get_onehot_representation(text, vocab = data_vocab):\n",
    "    onehot_encoded = []\n",
    "    for word in text:\n",
    "        temp = [0]*len(vocab)\n",
    "        temp[vocab.index(word)-1] = 1\n",
    "        onehot_encoded.append(temp)\n",
    "    return onehot_encoded\n",
    "\n",
    "print(\"One Hot Representation for sentence \\\"its one thing I dont know why it doesnt\\\" :\")\n",
    "get_onehot_representation(['its', 'one', 'thing', 'I', 'dont', 'know', 'why', 'it', 'dosent'], sample_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bd85cf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T06:41:08.889155Z",
     "iopub.status.busy": "2022-06-11T06:41:08.888360Z",
     "iopub.status.idle": "2022-06-11T06:41:08.893207Z",
     "shell.execute_reply": "2022-06-11T06:41:08.892317Z"
    },
    "papermill": {
     "duration": 0.014659,
     "end_time": "2022-06-11T06:41:08.895341",
     "exception": false,
     "start_time": "2022-06-11T06:41:08.880682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Vocabulary : 70948\n",
      "Sample of Vocabulary : ['16mar20', 'russia', 'surveillance', 'watchdog', 'reported', 'high', 'arctic', 'where', 'man', 'traveled']\n"
     ]
    }
   ],
   "source": [
    "print(f'Length of Vocabulary : {len(data_vocab)}')\n",
    "print(f'Sample of Vocabulary : {data_vocab[302 : 312]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4adb5dd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T06:41:08.911951Z",
     "iopub.status.busy": "2022-06-11T06:41:08.911310Z",
     "iopub.status.idle": "2022-06-11T06:41:09.087289Z",
     "shell.execute_reply": "2022-06-11T06:41:09.085830Z"
    },
    "papermill": {
     "duration": 0.186318,
     "end_time": "2022-06-11T06:41:09.089687",
     "exception": false,
     "start_time": "2022-06-11T06:41:08.903369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of a single sentence : (17, 70948)\n"
     ]
    }
   ],
   "source": [
    "sample_one_hot_rep = get_onehot_representation(df2.OriginalTweet[7], data_vocab)\n",
    "print(f\"Shapes of a single sentence : {np.array(sample_one_hot_rep).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3fd70c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T06:41:09.105163Z",
     "iopub.status.busy": "2022-06-11T06:41:09.104754Z",
     "iopub.status.idle": "2022-06-11T06:41:09.117281Z",
     "shell.execute_reply": "2022-06-11T06:41:09.116193Z"
    },
    "papermill": {
     "duration": 0.022581,
     "end_time": "2022-06-11T06:41:09.119334",
     "exception": false,
     "start_time": "2022-06-11T06:41:09.096753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary mapping for given sample corpus : \n",
      " {'its': 10, 'one': 15, 'thing': 18, 'dont': 2, 'know': 12, 'why': 23, 'it': 9, 'doesnt': 1, 'even': 4, 'matter': 13, 'how': 7, 'hard': 6, 'you': 24, 'try': 22, 'keep': 11, 'that': 17, 'in': 8, 'mind': 14, 'designed': 0, 'this': 19, 'rhyme': 16, 'to': 21, 'explain': 5, 'due': 3, 'time': 20}\n",
      "\n",
      "Bag of word Representation of sentence 'the cat cat sat in the hat'\n",
      "[[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "sample_bow = CountVectorizer()\n",
    "\n",
    "# sample_corpus = [['the', 'cat', 'sat'], \n",
    "#                  ['the', 'cat', 'sat', 'in', 'the', 'hat'],\n",
    "#                  ['the', 'cat', 'with', 'the', 'hat']]\n",
    "\n",
    "sample_corpus = [\"its one thing I dont know why\", \"it doesnt even matter how hard you try\", \"keep that in mind I designed this rhyme\", \"to explain in due time\"]\n",
    "\n",
    "sample_bow.fit(sample_corpus)\n",
    "\n",
    "def get_bow_representation(text):\n",
    "        return sample_bow.transform(text)\n",
    "    \n",
    "print(f\"Vocabulary mapping for given sample corpus : \\n {sample_bow.vocabulary_}\")\n",
    "print(\"\\nBag of word Representation of sentence 'the cat cat sat in the hat'\")\n",
    "print(get_bow_representation([\"the cat cat sat in the hat\"]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1201586c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T06:41:09.134471Z",
     "iopub.status.busy": "2022-06-11T06:41:09.134069Z",
     "iopub.status.idle": "2022-06-11T06:41:09.150953Z",
     "shell.execute_reply": "2022-06-11T06:41:09.149957Z"
    },
    "papermill": {
     "duration": 0.02725,
     "end_time": "2022-06-11T06:41:09.153274",
     "exception": false,
     "start_time": "2022-06-11T06:41:09.126024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vacabulary mapping for given sample corpus : \n",
      " {'the': 4, 'cat': 0, 'sat': 3, 'in': 2, 'hat': 1, 'with': 5}\n",
      "\n",
      "Bag of word Representation of sentence 'the the the the cat cat sat in the hat'\n",
      "[[1 1 1 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "sample_bow = CountVectorizer(binary = True)\n",
    "\n",
    "sample_corpus = [\"the cat sat\", \"the cat sat in the hat\", \"the cat with the hat\"]\n",
    "\n",
    "sample_bow.fit(sample_corpus)\n",
    "\n",
    "def get_bow_representation(text):\n",
    "        return sample_bow.transform(text)\n",
    "    \n",
    "print(f\"Vacabulary mapping for given sample corpus : \\n {sample_bow.vocabulary_}\")\n",
    "print(\"\\nBag of word Representation of sentence 'the the the the cat cat sat in the hat'\")\n",
    "print(get_bow_representation([\"the the the the cat cat sat in the hat\"]).toarray())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 156.971725,
   "end_time": "2022-06-11T06:41:09.981635",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-11T06:38:33.009910",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
